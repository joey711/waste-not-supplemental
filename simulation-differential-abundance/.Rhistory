library("edgeR")
?DGEList
?==
?"=="
library("phyloseq"); packageVersion("phyloseq")
library("edgeR"); packageVersion("edgeR")
?calcNormFactors
?edgeR
data("GlobalPatterns")
#' Convert phyloseq OTU count data into DGEList for edgeR package
phyloseq_to_edgeR = function(physeq, group, method="RLE", ...){
require("edgeR")
require("phyloseq")
# Enforce orientation.
if( !taxa_are_rows(physeq) ){ physeq <- t(physeq) }
x = as(otu_table(physeq), "matrix")
# Add one to protect against overflow, log(0) issues.
x = x + 1
# Check `group` argument
if( identical(all.equal(length(group), 1), TRUE) & nsamples(physeq) > 1 ){
# Assume that group was a sample variable name (must be categorical)
group = get_variable(physeq, group)
}
# Now turn into a DGEList
y = DGEList(counts=x, group=group, remove.zeros=TRUE, ...)
# Calculate the normalization factors
z = calcNormFactors(y, method=method)
# Check for division by zero inside `calcNormFactors`
if( !all(is.finite(z$samples$norm.factors)) ){
stop("Something wrong with edgeR::calcNormFactors on this data,
non-finite $norm.factors, consider changing `method` argument")
}
# Estimate dispersions
return(estimateTagwiseDisp(estimateCommonDisp(z)))
}
GP = prune_taxa(names(sort(taxa_sums(GlobalPatterns), decreasing=TRUE)[1:500]), GlobalPatterns)
gpdge = phyloseq_to_edgeR(GlobalPatterns)
sample_variables(GP)
get_variable(GP, "SampleType")
?exactTest
?topTags
gpdge
gpdge = phyloseq_to_edgeR(GlobalPatterns, group="SampleType")
?GlobalPatterns
data("GlobalPatterns")
GP = prune_taxa(names(sort(taxa_sums(GlobalPatterns), decreasing=TRUE)[1:500]), GlobalPatterns)
sample_data(GP)$human <- ifelse(get_variable(GP, "SampleType") %in% c("Feces", "Mock", "Skin", "Tongue"), "human-assoc", "non-human")
sample_data(GP)$human
gpdge = phyloseq_to_edgeR(GlobalPatterns, group="human")
gpdge = phyloseq_to_edgeR(GP, group="human")
gpdge = phyloseq_to_edgeR(GP, group="human")
gpdge
et = exactTest(gpdge)
tt = topTags(et, n=nrow(gpdge$table), adjust.method="BH", sort.by="PValue")
res = tt@.Data[[1]]
res
colnames(res)
res[, "FDR"]
?phyloseq
filepath = system.file("extdata", "study_1457_split_library_seqs_and_mapping.zip",
package = "phyloseq")
kostic = microbio_me_qiime(filepath)
get_variable(kostic, "DIAGNOSIS")
which(get_variable(kostic, "DIAGNOSIS") == "None")
kosticB = subset_samples(kostic, DIAGNOSIS != "None")
get_variable(kosticB, "DIAGNOSIS")
dge = phyloseq_to_edgeR(kosticB, group="DIAGNOSIS")
# Perform binary test
et = exactTest(dge)
tt = topTags(et, n=nrow(gpdge$table), adjust.method="BH", sort.by="PValue")
res = tt@.Data[[1]]
res[, "FDR"]
res = tt@.Data[[1]]
alpha = 0.01
sigtab = res[(res$FDR < alpha), ]
sigtab = cbind(as(sigtab, "data.frame"), as(tax_table(kostic)[rownames(sigtab), ], "matrix"))
rownames(sigtab)
head(sigtab)
library("ggplot2")
theme_set(theme_bw())
scale_fill_discrete <- function(palname = "Set1", ...) {
scale_fill_brewer(palette = palname, ...)
}
sigtabgen = subset(sigtab, !is.na(Genus))
# Phylum order
x = tapply(sigtabgen$log2FoldChange, sigtabgen$Phylum, function(x) max(x))
x = sort(x, TRUE)
sigtabgen$Phylum = factor(as.character(sigtabgen$Phylum), levels = names(x))
# Genus order
x = tapply(sigtabgen$log2FoldChange, sigtabgen$Genus, function(x) max(x))
x = sort(x, TRUE)
sigtabgen$Genus = factor(as.character(sigtabgen$Genus), levels = names(x))
ggplot(sigtabgen, aes(x = Genus, y = log2FoldChange, fill = Phylum)) + geom_bar(stat = "identity",
position = "dodge", color = "black") + theme(axis.text.x = element_text(angle = -90,
hjust = 0, vjust = 0.5))
library("ggplot2")
theme_set(theme_bw())
scale_fill_discrete <- function(palname = "Set1", ...) {
scale_fill_brewer(palette = palname, ...)
}
sigtabgen = subset(sigtab, !is.na(Genus))
# Phylum order
x = tapply(sigtabgen$logFC, sigtabgen$Phylum, function(x) max(x))
x = sort(x, TRUE)
sigtabgen$Phylum = factor(as.character(sigtabgen$Phylum), levels = names(x))
# Genus order
x = tapply(sigtabgen$logFC, sigtabgen$Genus, function(x) max(x))
x = sort(x, TRUE)
sigtabgen$Genus = factor(as.character(sigtabgen$Genus), levels = names(x))
ggplot(sigtabgen, aes(x = Genus, y = logFC, fill = Phylum)) + geom_bar(stat = "identity",
position = "dodge", color = "black") + theme(axis.text.x = element_text(angle = -90,
hjust = 0, vjust = 0.5))
?geom_bar
ggplot(sigtabgen, aes(x = Genus, y = logFC, color = Phylum)) + geom_point(size=6) +
theme(axis.text.x = element_text(angle = -90, hjust = 0, vjust = 0.5))
getwd()
# The required package list:
reqpkg = c("cluster", "doParallel", "edgeR", "DESeq", "DESeq2", "foreach",
"ggplot2", "grid", "scales", "metagenomeSeq", "phyloseq", "plyr", "reshape2", "ROCR")
# Load all required packages and show version
for(i in reqpkg){
print(i); print(packageVersion(i))
library(i, quietly=TRUE, verbose=FALSE, warn.conflicts=FALSE, character.only=TRUE)
}
theme_set(theme_bw())
pal = "Set1"
scale_colour_discrete <-  function(palname=pal, ...){
scale_colour_brewer(palette=palname, ...)
}
scale_fill_discrete <-  function(palname=pal, ...){
scale_fill_brewer(palette=palname, ...)
}
load("/Volumes/media/Research/normalization_trials/simulation-differential-abundance-Thu-Dec-5-11_31_17-2013.RData")
eval_res_list = function(resi, NTP){
require("ROCR")
# Some DESeq2 results (for example) had NA adjusted p-values
# Replace NA $padj values to highest possible value (1.0)
resi[is.na(resi[, "padj"]), "padj"] <- 1.0
# Evaluate detection performance.
wh.pred = (resi[, "padj"] < 0.05)
wh.pos = which(wh.pred)
wh.neg = which(!wh.pred)
wh.TP = grep("[[:print:]]+\\-TP$", resi[, "id"])
FPs = sum(!wh.pos %in% wh.TP)
TPs = sum(wh.pos %in% wh.TP)
TNs = sum(!wh.neg %in% wh.TP) #nrow(resi) - NTP
FNs = sum(wh.neg %in% wh.TP)
Power = TPs/NTP
# Sensitivity: True Positives divided by all positives (sum of true positives and false negatives)
Sensitivity = TPs / (TPs + FNs)
# Specificity: True negatives divided by all negatives (sum of true negatives and false positives)
Specificity = TNs / (TNs + FPs)
# c(FP=FPs, TP=TPs, Power=Power)
wh.truth = (1:nrow(resi) %in% wh.TP)
pred <- prediction(as.numeric(wh.pred), factor(wh.truth))
#perf <- performance(pred, "tpr", "fpr")
AUC = performance(pred, "auc")@y.values[[1]]
return(c(FP=FPs, TP=TPs, Power=Power, AUC=AUC, Specificity=Specificity, Sensitivity=Sensitivity))
}
# Put every results list into a coherently-named superlist.
superlist = list(DESeq=DESeqreslist, rare_DESeq=rare_DESeqreslist,
DESeq2=DESeq2reslist, rare_DESeq2=rare_DESeq2reslist,
nonorm_mt=nonorm_reslist, rare_mt=raremt_reslist, prop_mt=propmt_reslist,
metagenomeSeq=MGSreslist, rare_metagenomeSeq=rareMGSreslist,
edgeR=edgeRreslist, rare_edgeR=rare_edgeRreslist)
# Use foreach to organize all this data into a list of data.frames
perfdflist = foreach(resultslist = superlist) %dopar% {
perflist <- lapply(resultslist, eval_res_list, NTP=nTP)
if( is.null(names(resultslist)) ){
names(perflist) <- simparams
} else {
names(perflist) <- names(resultslist)
}
perfdf = make_power_df(perflist, comdelim, simparamslabels)
return(perfdf)
}
names(perfdflist) <- names(superlist)
df = ldply(perfdflist)
colnames(df)[1] <- "Approach"
# Define whether or not counts were rarefied prior to testing.
df$Normalization <- "Model/None"
df$Normalization[grep("rare_", df$Approach, fixed=TRUE)] <- "Rarefied"
df$Normalization[grep("prop_", df$Approach, fixed=TRUE)] <- "Proportion"
df$Method <- gsub("^[[:alpha:]]+\\_", "", df$Approach)
# Some additional adjustments
df$nsamples <- as.numeric(df$nsamples)
df$EffectSize <- as.numeric(df$EffectSize)
df$FP <- df$FP/(nTP + df$FP)
nonrepvars = c("Approach", "Normalization", "Method", simparamslabels[!simparamslabels%in%c("Replicate")])
dfmeansd = ddply(df, nonrepvars[nonrepvars!="SampleType"], function(x, vars){
xdf = data.frame(x[1, nonrepvars, drop=FALSE], AUC=mean(x$AUC), sd.AUC=sd(x$AUC))
xdf = cbind(xdf, Shannon=mean(x$Shannon), InvSimpson=mean(x$InvSimpson))
xdf = cbind(xdf, FP=mean(x$FP), sd.FP=sd(x$FP))
xdf = cbind(xdf, Power=mean(x$Power), sd.Power=sd(x$Power))
xdf = cbind(xdf, Sensitivity=mean(x$Sensitivity), sd.Sensitivity=sd(x$Sensitivity))
xdf = cbind(xdf, Specificity=mean(x$Specificity), sd.Specificity=sd(x$Specificity))
return(xdf)
}, vars=nonrepvars[nonrepvars!="SampleType"])
maindat = transform(dfmeansd, group=paste0(nsamples, Normalization, Method))
nreadskeep = c(2000, 50000)
pAUCzero = ggplot(dfmeansd, aes(EffectSize, AUC, color=Normalization)) +
geom_path(size=1) +
geom_errorbar(aes(ymax=AUC+sd.AUC, ymin=AUC-sd.AUC), width=0.0, alpha=0.5, size=2) +
facet_grid(nreads + nsamples ~ Method) +
ggtitle("Differential Abundance Detection Performance") +
scale_y_continuous(breaks=c(0.6, 0.8, 1.0)) +
coord_cartesian(ylim=c(0.5, 1))
print(pAUCzero)
nreadskeep = c(2000, 50000)
maindat = transform(dfmeansd, group=paste0(nsamples, Normalization, Method))
pAUCmain = ggplot(maindat, aes(EffectSize, AUC, color=Normalization,
alpha=factor(nsamples))) +
geom_path(size=0.5, aes(group=group)) +
geom_errorbar(aes(ymax=AUC+sd.AUC, ymin=AUC-sd.AUC), width=0.2, alpha=0.25, size=0.35, position="dodge") +
geom_point(aes(shape = Normalization), size = 1.5) +
scale_alpha_discrete(range=c(1, 0.4), guide = guide_legend(title = "Samples/Class")) +
facet_grid(nreads ~ Method) +
scale_y_continuous(breaks=c(0.6, 0.8, 1.0)) +
coord_cartesian(ylim=c(0.5, 1)) +
theme(text=element_text(size=8)) +
ggtitle("Differential Abundance Detection Performance")
print(pAUCmain)
# Subset for main figure include in manuscript
pAUCmain$data <- subset(pAUCmain$data, as.numeric(nreads) %in% nreadskeep)
print(pAUCmain)
pDAFP = ggplot(dfmeansd, aes(EffectSize, FP, color=Normalization)) +
geom_path(size=0.5) +
geom_errorbar(aes(ymax=FP+sd.FP, ymin=FP-sd.FP), width=0.2, alpha=0.25, size=0.35, position="dodge") +
geom_point(aes(shape = Normalization), size = 1.5) +
facet_grid(nreads + nsamples ~ Method) +
scale_y_continuous(breaks=c(0.2, 0.5, 0.8)) +
coord_cartesian(ylim=c(0, 1)) +
ylab("False Positive Rate") +
ggtitle("Differential Abundance Detection Performance, False Positives")
print(pDAFP)
pDApower = ggplot(dfmeansd, aes(EffectSize, Power, color=Normalization)) +
geom_path(size=0.5) +
geom_errorbar(aes(ymax=Power+sd.Power, ymin=Power-sd.Power), width=0.2, alpha=0.25, size=0.35, position="dodge") +
geom_point(aes(shape = Normalization), size = 1.5) +
facet_grid(nreads + nsamples ~ Method) +
scale_y_continuous(breaks=c(0.2, 0.5, 0.8)) +
coord_cartesian(ylim=c(0, 1)) +
ylab("Power") +
ggtitle("Differential Abundance Detection Performance, Power")
print(pDApower)
# Set aside a copy that you will modify for plotting
maindat2 = maindat
# Rename the test method by package and function name
maindat2$Method <- gsub("^DESeq$", "'DESeq - nbinomTest'", maindat2$Method)
maindat2$Method <- gsub("^DESeq2$", "'DESeq2 - nbinomWaldTest'", maindat2$Method)
maindat2$Method <- gsub("^edgeR$", "'edgeR - exactTest'", maindat2$Method)
maindat2$Method <- gsub("^metagenomeSeq$", "'metagenomeSeq - fitZig'", maindat2$Method)
maindat2$Method <- gsub("^mt$", "'two sided Welch t-test'", maindat2$Method)
# Rename the library size to include plotmath symbol for clarity
lib_labels = paste0("tilde(N)[L]==", sort(unique(as.integer(maindat2$nreads))) )
lib_levels = sort(unique(as.character(maindat2$nreads)))
maindat2$nreads <- factor(maindat2$nreads, levels=lib_levels, labels=lib_labels)
# Re-order the normalization levels
maindat2$Normalization <- factor(maindat2$Normalization, levels=c("Model/None", "Rarefied", "Proportion"))
pathsize = 0.5
pointsize = 1.5
errorwidth = 0.2
erroralpha = 0.25
errorsize = 0.35
plotlabtextsize = 7
nsampleslegtitle = "Number Samples per Class:"
normlegtitle = "Normalization Method:"
pAUCmain = ggplot(maindat2, aes(EffectSize, AUC, color=Normalization)) +
geom_path(size=pathsize, aes(group=group, alpha=factor(nsamples))) +
geom_errorbar(aes(ymax=AUC+sd.AUC, ymin=AUC-sd.AUC), width=errorwidth, alpha=erroralpha, size=errorsize, position="dodge") +
geom_point(aes(shape=Normalization), size=pointsize) +
facet_grid(nreads ~ Method, labeller=label_parsed) +
scale_alpha_discrete(range=c(1, 0.4), guide = guide_legend(title=nsampleslegtitle)) +
scale_colour_discrete(guide=guide_legend(title=normlegtitle)) +
scale_shape_discrete(guide=guide_legend(title=normlegtitle)) +
scale_y_continuous(breaks=c(0.6, 0.8, 1.0), limits=c(0.5, 1.0), oob=function(x,limits){x}) +
coord_cartesian(ylim=c(0.5, 1)) +
ggtitle("Differential Abundance Detection Performance (AUC)")
pAUCmain
# re-plot as function of alpha diversity (Shannon), use full (non-averaged) df
pAUCshan = pAUCmain %+% df
pAUCshan$mapping$x <- as.name("Shannon")
pAUCshan$labels$title <- "AUC versus Shannon Index"
pAUCshan$labels$x <- "Shannon Index"
pAUCshan$layers <- pAUCshan$layers[-(1:2)]
pAUCshan
# Specificity plot
pSpecificity = ggplot(maindat2, aes(EffectSize, Specificity, color=Normalization, alpha=factor(nsamples))) +
geom_path(size=pathsize, aes(group=group)) +
geom_errorbar(aes(ymax=Specificity+sd.Specificity, ymin=Specificity-sd.Specificity),
width=errorwidth, alpha=erroralpha, size=errorsize, position="dodge") +
geom_point(aes(shape=Normalization), size=pointsize) +
facet_grid(nreads ~ Method, labeller=label_parsed) +
scale_alpha_discrete(range=c(1, 0.4), guide = guide_legend(title=nsampleslegtitle)) +
scale_colour_discrete(guide=guide_legend(title=normlegtitle)) +
scale_shape_discrete(guide=guide_legend(title=normlegtitle)) +
scale_y_continuous(breaks=c(0.6, 0.8, 1.0), limits=c(0.5, 1.0), oob=function(x,limits){x}) +
ggtitle("Differential Abundance Specificity")
pSpecificity
# re-plot as function of alpha diversity (Shannon Index)
pSpecificityShan = pSpecificity %+% df
pSpecificityShan$mapping$x <- as.name("Shannon")
pSpecificityShan$labels$title <- "Specificity versus Shannon Index"
pSpecificityShan$labels$x <- "Shannon Index"
pSpecificityShan$layers <- pSpecificityShan$layers[-(1:2)]
pSpecificityShan
# Sensitivity plot
pSensitivity = ggplot(maindat2, aes(EffectSize, Sensitivity, color=Normalization, alpha=factor(nsamples))) +
geom_path(size=pathsize, aes(group=group)) +
geom_errorbar(aes(ymax=Sensitivity+sd.Sensitivity, ymin=Sensitivity-sd.Sensitivity),
width=errorwidth, alpha=erroralpha, size=errorsize, position="dodge") +
geom_point(aes(shape=Normalization), size=pointsize) +
facet_grid(nreads ~ Method, labeller=label_parsed) +
scale_alpha_discrete(range=c(1, 0.4), guide = guide_legend(title=nsampleslegtitle)) +
scale_colour_discrete(guide=guide_legend(title=normlegtitle)) +
scale_shape_discrete(guide=guide_legend(title=normlegtitle)) +
scale_y_continuous(breaks=c(0.2, 0.5, 0.8, 1.0), limits=c(0, 1.0), oob=function(x,limits){x}) +
xlab("Effect Size") + ggtitle("Differential Abundance Sensitivity")
pSensitivity
# re-plot as function of alpha diversity (Shannon Index)
pSensitivityShan = pSensitivity %+% df
pSensitivityShan$mapping$x <- as.name("Shannon")
pSensitivityShan$labels$title <- "Sensitivity versus Shannon Index"
pSensitivityShan$labels$x <- "Shannon Index"
pSensitivityShan$layers <- pSensitivityShan$layers[-(1:2)]
pSensitivityShan
# Remove main title
pAUCmain$labels$title <- NULL
pSpecificity$labels$title <- NULL
pSensitivity$labels$title <- NULL
# Remove margins
pAUCmain = pAUCmain + theme(text=element_text(size=plotlabtextsize), plot.margin=unit(c(0, 0, 0, 0), "cm"),
legend.position="top", legend.box="horizontal", legend.margin=unit(-0.5, "cm"))
pSpecificity = pSpecificity + theme(text=element_text(size=plotlabtextsize), plot.margin=unit(c(0, 0, 0, 0), "cm"))
pSensitivity = pSensitivity + theme(text=element_text(size=plotlabtextsize), plot.margin=unit(c(0, 0, 0, 0), "cm"))
# Remove horizontal axis labels from pSpecificity and pAUCmain
pAUCmain = pAUCmain + theme(axis.text.x=element_blank(), axis.title.x=element_blank(), plot.margin=unit(c(0, 0, -0.4, 0), "cm"))
pSpecificity = pSpecificity + theme(axis.text.x=element_blank(), axis.title.x=element_blank(), plot.margin=unit(c(0, 0, -0.4, 0), "cm"))
# Remove redundant x-labels, legends
pAUCmain = pAUCmain + theme(strip.background=element_blank())
pSpecificity = pSpecificity + theme(legend.position="none", strip.text.x=element_blank(), strip.background=element_blank())
pSensitivity = pSensitivity + theme(legend.position="none", strip.text.x=element_blank(), strip.background=element_blank())
# Subset for main figure include in manuscript
pAUCmain$data <- pAUCmain$data[(pAUCmain$data$nreads %in%
c("tilde(N)[L]==2000", "tilde(N)[L]==50000")), ]
pSpecificity$data <- pSpecificity$data[pSpecificity$data$nreads %in% "tilde(N)[L]==50000", ]
pSensitivity$data <- pSensitivity$data[pSensitivity$data$nreads %in% "tilde(N)[L]==50000", ]
# Create multi-plot grid layout
Layout = grid.layout(3, 1, heights=c(3, 1, 1.2))
grid.show.layout(Layout)
grid.newpage()
pushViewport(viewport(layout = Layout))
print(pAUCmain, vp=viewport(layout.pos.row=1, layout.pos.col=1))
print(pSpecificity, vp=viewport(layout.pos.row=2, layout.pos.col=1))
print(pSensitivity, vp=viewport(layout.pos.row=3, layout.pos.col=1))
95/(95+5)
nTP
5/(30 + 5)
10/(30 + 10)
